---
title: "Homework 2"
author: "Allison Randy-Cofie"
date: "2022-09-29"
output: github_document
---


```{r setup, message=FALSE}
library(tidyverse)
library(readxl)
```

### Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv(
    "./nyc_transit.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

There are 465 distinct stations with 84 being ADA compliant. The proportion of station entrances/ exits without vending is 0.377. 
60 distinct stations serve the A train and of the 60, 17 of them are ADA compliant.


### Problem 2

Load the datasets
```{r}
mr_df <- read_excel("./Trash Wheel Collection Data.xlsx","Mr. Trash Wheel","A2:N549")%>%
 janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(sports_balls=as.integer(sports_balls)) %>% 
   mutate(trash_wheel = "mr")
```

```{r}
prof_df <- read_excel("./Trash Wheel Collection Data.xlsx","Professor Trash Wheel","A2:M96")%>%
 janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
   mutate(trash_wheel = "prof") %>% 
  mutate(year=as.character(year))
```

Combining the data
```{r}
trash_df <- bind_rows(mr_df,prof_df)
```
In the Mr. Trash Wheel data set there are `r nrow(mr_df)` observations and `r ncol(mr_df)` variables. Some of the key variables in this dataset are Weight of trash in tons and the volume of trash in cubic yards. The total number of sports balls collected in 2020 by Mr. Trash Wheel is `r mr_df %>% filter(year == 2020) %>% summarize(sum(sports_balls))`.

In the Professor Trash Wheel data set there are `r nrow(prof_df)` observations and `r ncol(prof_df)` variables. Some of the key variables in this dataset are Weight of trash in tons and the volume of trash in cubic yards. The total weight of trash collected by Professor Trash Wheel is `r prof_df %>%summarize(sum(weight_tons))` tons.


### Problem 3

Load the datasets and clean them
```{r, message=FALSE}
pols_df <- read_csv("./fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year","month","day")) %>% 
  mutate(month = month.abb[as.numeric(month)],
  president = recode(prez_dem, `1` = "dem", `0` = "gop")) %>% 
  select(-c(prez_gop, prez_dem, day)) 
```

```{r, message=FALSE}
snp_df <- read_csv("./fivethirtyeight_datasets/snp.csv") 
dates <- snp_df$date %>% 
  as.Date(., "%m/%d/%y") %>%  
  as.Date(ifelse(dates > Sys.Date(), format(dates, "19%y-%m-%d"), format(dates)))
snp_df$date = dates

snp_df <- snp_df %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year","month","day")) %>% 
  mutate(month = month.abb[as.numeric(month)]) %>% 
  arrange(year, month) %>% 
  relocate(year, month)
```

```{r, message=FALSE}
unemp_df<- read_csv("./fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>%
   pivot_longer(
    jan:dec, 
    names_to = "month",
    values_to = "unemployment_rate"
  ) %>% 
  arrange(year, month) %>% 
  relocate(year, month) %>% 
  mutate(year = as.character(year))
```


Putting the datasets together
```{r}
final_df <- 
  pols_df %>% 
  left_join(snp_df, by = c("year","month")) %>% 
  left_join(unemp_df, by = c("year", "month"))


```

The `pols-month.csv` dataset contains information about politicians and the number of which are democratic or republican govenors or senators. After cleaning it has `r nrow(pols_df)` observations and `r ncol(pols_df)` variables. The `snp.csv` dataset contains information about the stock S&P's closing value for each day of observation. After cleaning, this data set has `r nrow(snp_df)` observations and `r ncol(snp_df)` variables. The `unemployment.csv` dataset contains information about the unemployment rate for each month throughout the years in the dataset. After cleaning, this dataset has 
`r nrow(unemp_df)` observations and `r ncol(unemp_df)` variables. 


After combining the datasets, the resulting data set contains `r nrow(final_df)` observations and `r ncol(final_df)` variables. The years included in the combined dataset range from `r min(final_df$year)` to `r max(final_df$year)`. Some of the key variables are `president`, `close`, and `unemp_rate`.